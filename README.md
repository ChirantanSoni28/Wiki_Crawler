# Web Crawler | Wikipedia
    A web crawler (also known as a web spider or web robot) is a program or automated script which browses the World Wide Web in a methodical, automated manner. This process is called Web crawling or spidering.

    This project involves Wikipedia-Crawler, in which user inputs a start URL and End URL to generate list of URL that lies between them.
